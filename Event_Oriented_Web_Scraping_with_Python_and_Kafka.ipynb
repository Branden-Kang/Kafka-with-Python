{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO1vkuegyqPy8rDj8hjSX01"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[Reference](https://medium.com/@Divithraju/event-oriented-web-scraping-with-python-and-kafka-6f37267818f6)"
      ],
      "metadata": {
        "id": "ShesJ2yDCTr_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install kafka"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8fpXnazCgc9",
        "outputId": "bb6b4235-e149-4dc3-c0d5-f593de043f44"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kafka\n",
            "  Downloading kafka-1.3.5-py2.py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.2/207.2 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: kafka\n",
            "Successfully installed kafka-1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3FjVQDPKCPPz"
      },
      "outputs": [],
      "source": [
        "from kafka import KafkaProducer\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import time\n",
        "\n",
        "# Kafka configuration\n",
        "bootstrap_servers = ['localhost:9092']\n",
        "topic = 'scraping-events'\n",
        "\n",
        "# Web scraper configuration\n",
        "product_url = 'https://www.domain.com/product-page'\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
        "\n",
        "# Create Kafka producer\n",
        "producer = KafkaProducer(bootstrap_servers=bootstrap_servers)\n",
        "\n",
        "def scrape_product_price():\n",
        "    # Make HTTP request to fetch the product page\n",
        "    response = requests.get(product_url, headers=headers)\n",
        "\n",
        "    # Parse the HTML response\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "    # Extract the product price from the parsed HTML\n",
        "    price_element = soup.find('span', {'class': 'product-price'})\n",
        "    price = price_element.text.strip() if price_element else 'N/A'\n",
        "\n",
        "    # Create a scraping event message\n",
        "    scraping_event = {\n",
        "        'timestamp': int(time.time()),\n",
        "        'product_url': product_url,\n",
        "        'price': price\n",
        "    }\n",
        "\n",
        "    # Publish the scraping event to Kafka topic\n",
        "    producer.send(topic, value=scraping_event)\n",
        "    producer.flush()\n",
        "    print('Scraping event published:', scraping_event)\n",
        "\n",
        "# Run the scraper at regular intervals\n",
        "while True:\n",
        "    scrape_product_price()\n",
        "    time.sleep(300)\n",
        "# Scrapes every 5 minutes"
      ]
    }
  ]
}